---
title: "cfb"
output: html_document
date: "2022-09-23"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Load tidyverse
```{r}
library(tidyverse)
library(dplyr)
library(Hmisc)

```

#Load college football game data from http://mattwaite.github.io/sportsdatafiles/footballlogs1121.csv (Links to an external site.) into a variable called `logs` and examine it so that you understand the column names.

```{r}
logs <- read_csv("http://mattwaite.github.io/sportsdatafiles/footballlogs1121.csv")

head(logs)
```
#Create a new column for point differential between the TeamScore and OpponentScore using mutate. You can use the same `logs` variable.
```{r}
logs <- mutate(logs, differential = TeamScore - OpponentScore)
 
```

#Create a regression (a linear model, like we did in this chapter (Links to an external site.)) investigating whether the number of penalties can predict the score differential.

```{r}
fit <- lm(differential ~ Penalties, data = logs)
summary(fit)

```
# In a paragraph below this code block, describe the results: what is the p-value, and does it mean the results are random? Using the r-squared value, how much of the differential can be explained by penalties? How useful is this regression?

The p-value is below 0.5, which tells us that the relationship is statistically significant. The R-squared value is quite close to zero, which tells us that penalties aren't a good predictor for team penalties.

```{r}
#Here's an extra model on penalty yards

fit <- lm(differential ~ PenaltyYds, data = logs)
summary(fit)

```
Explanation: The p-value is less than 0.5, so this relationship is statistically significant. The R-squared value is very close to zero, so we can tell that penalty yards are not a good predictor for differential either.


#Next, create a multiple regression model following the examples in this chapter (Links to an external site.). Instead of using the number of penalties alone, combine other numeric columns that describe mistakes/bad outcomes to try and predict the score differential with a higher degree of confidence. Look at the same values in the results you did before, but also take into account the residual standard error and the risk of multicollinearity - are you adding columns that explain each other instead of the differential? Below this code block, explain your choices and what you think the results say.
```{r}

#Create new variables
logs <- mutate(logs, TurnoverMargin = TotalTurnovers - DefTotalTurnovers)
logs <- mutate(logs, FumbleMargin = Fumbles - DefFumbles)
logs <- mutate(logs, RushingMargin = RushingYds - DefRushingYds)
logs <- mutate(logs, PassingMargin = PassingYds - DefPassingYds)
logs <- mutate(logs, FDRushMargin = FirstDownRush - DefFirstDownRush)

#Create model
model1 <- lm(differential ~ TurnoverMargin + RushingMargin + PassingMargin, data=logs)
summary(model1)
```
```{r}

#Check for multicollinearity

simplelogs <- logs %>% select_if(is.numeric) %>% select(-Game) %>% select(differential, TurnoverMargin, RushingMargin, PassingMargin)

cormatrix <- rcorr(as.matrix(simplelogs))

cormatrix$r

```
Explanation: The p-value is less than 0.5, which tells us that we're looking at something statistically significant. The R-squared value, which isn't too far from one, tells us that turnover margin, rushing margin and passing margin make a solid predictor for winning. In other words, if a team is passing more than the opponent, getting more turnovers than the opponent and rushing more than the opponent, then there's a pretty good chance that team is also going to win. If we're seeking a model that specifically predicts the differential based on bad outcomes/mistakes, than this is not the best for that. This model explicitly puts things together that one might would assume would help a team win a game. 

#Finally, use filter to narrow the game data so that you're only working with games that are close (you'll need to define what "close" means). Are your simple or multiple regression models better? Worse? Below this code block, explain your choices and what you think the results say.

```{r}
#Scratch code for ideas on calculating closeness
min(logs$differential)
median(logs$differential)
(max(logs$differential) - min(logs$differential))/4
min(logs$differential) + 40.5
mean(logs$differential)
```


```{r}
#Define close games as those were won or lost by a margin between -5 and 5
closeGames <- filter(logs, differential %in% -5:5)

```

```{r}
#Multiple regression model
model2 <- lm(differential ~ TurnoverMargin + RushingMargin + PassingMargin, data=closeGames)
summary(model2)
```


```{r}
#Simple regression model
fit2 <- lm(differential ~ Penalties, data = closeGames)
summary(fit2)


```
Explanation of simple vs. multiple regression models: The multiple regression model is better than the simple regression model when looking at close games, or games when the victor is determined by 5 points or less. The simple regression model is not statistically significant, as seen by the p-value greater than 0.5. The p-value for the multiple regression model is statistically significant, but the r-squared value tells us that the selected elements are no longer strong predictors of the differential. When looking at all of the games at all degrees of closeness, the multiple regression model was way stronger than it is when looking at only close games. These findings could suggest that games that are closer aren't won in turnovers, rushing or passing more than the opponent. 

#At the end of all that code, summarize what you've learned about the relationship between penalties and point differential and whether you think there's a story there or whether it's useful in adding context within a larger story. Would you use this in journalism and, if so, how?

Penalties are not a strong predictor of point differential. From the first model created in this assignment, it was clear that penalties aren't prediction point differentials. I don't think there's a story on this. When I combined a ton of other variables, including turnover margin, passing margin and rushing margin, I was able to create a regression that is a solid predictor of the point differential. This model has a solid R-squared when looking at all of the games, but it falters when we look at only close games, which I defined as games won or lost by 5 points. I initially thought the model was pretty strong, but it was interesting to see it struggle so much in the filtered data. Teams that are closer are not won by having more turnovers, and more passing and rushing than the opponent.

Still, I think the multiple regression model could be a valuable way  to predict game outcomes as the data in a given game unfolds. It could be applied to something like the ESPN percentage chance of winning, which changes based on stats as the game goes on. I could imagine seeing the rise in turnovers, passing and rushing making it more likely that one team would win. At the same time, I think it's important to recognize that this model just isn't too surprising, which is why it might be hard to pull a story out of it. It seems kind of intuitive that teams that out-rush and out-pass their opponents would also win by more points. The turnover margin might be something to investigate more on its own down the line, though. A wide turnover margin makes it seem like one team is just outplaying the other physically. There's definitely more research to be done there, and maybe a jumping off point for a story down the line.